{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "648c3a63-cf36-486d-a1e0-c225d1f46925",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30644ae-8d68-444d-94d0-19b4ae2670f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.discrete.discrete_model import NegativeBinomial\n",
    "from statsmodels.discrete.discrete_model import Poisson as PoisDM\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning, HessianInversionWarning\n",
    "from sklearn.linear_model import PoissonRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c9343-df60-4787-8c1e-a955cd7bfc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "FUTURE_SRC_DIR = Path(\"processed_tmp/future\") # Directory where training data is stored\n",
    "ENGINE = \"fastparquet\" # Reading method\n",
    "DATE_COL = \"sold_date\"\n",
    "BAN_COLS_COMMON = {DATE_COL}\n",
    "BAN_PREFIXES = []\n",
    "\n",
    "TARGET_BASE = \"future_sales\"\n",
    "H_TARGET_FMT = TARGET_BASE + \"_{}\"\n",
    "SUM_TARGET = \"future_sales_sum\"\n",
    "\n",
    "K_CANDIDATES = list(range(60, 301, 60)) # List of numbers of features to select\n",
    "NB_TOP = 60 # Number of features to use for NB or Poisson model regression\n",
    "\n",
    "LGB_NUM_BOOST_ROUND = 8000 # Maximum number of LightGBM training epochs\n",
    "LGB_EARLY_STOP_ROUNDS = 200 # Number of epochs for LightGBM Early Stopping\n",
    "RANDOM_SEED = 1234\n",
    "\n",
    "# Set categorical variables\n",
    "CAT_INT_COLS = [\"jan_code\", \"store_name\", \"中分類名\", \"price_category\"]\n",
    "\n",
    "# Settings for outlier handling (upper and lower bounds)\n",
    "WINSOR_LO_Q = 0.5 / 100\n",
    "WINSOR_HI_Q = 99.5 / 100\n",
    "# Setting for the position of the value used as the reference for arcsinh scaling\n",
    "ASINH_Q = 0.90\n",
    "\n",
    "# --- Output directory settings ---\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "ROOT_OUT_DIR = Path(f\"lgb_nb_stacking_kgrid_all_{RUN_TAG}\")\n",
    "ROOT_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EVAL_OUT = ROOT_OUT_DIR / \"eval_results\"\n",
    "EVAL_OUT.mkdir(parents=True, exist_ok=True)\n",
    "EVAL_CSV_PATH = EVAL_OUT / \"metrics_all_tasks.csv\"\n",
    "EVAL_JSON_PATH = EVAL_OUT / \"metrics_summary.json\"\n",
    "\n",
    "print(f\"Output directory created: {ROOT_OUT_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e08ab32-0e19-4273-8e78-ad297daa9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(obj: Any, path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_src_df(task: str) -> Tuple[pd.DataFrame, str]:\n",
    "    \"\"\"Load task-specific data (exclude only target variable NaN, keep others)\"\"\"\n",
    "    if task == \"sum\":\n",
    "        src_path = FUTURE_SRC_DIR / \"future_sum26.parquet\"\n",
    "        target = SUM_TARGET\n",
    "    else:\n",
    "        N = int(task[1:])\n",
    "        src_path = FUTURE_SRC_DIR / f\"future_h{N}.parquet\"\n",
    "        target = H_TARGET_FMT.format(N)\n",
    "\n",
    "    print(f\"      Loading data: {src_path}\")\n",
    "    if not src_path.exists():\n",
    "        raise FileNotFoundError(f\"{src_path} not found.\")\n",
    "\n",
    "    df = pd.read_parquet(src_path, engine=ENGINE)\n",
    "    print(f\"      - Completed: {len(df):,} rows × {len(df.columns)} columns\")\n",
    "    \n",
    "    if DATE_COL not in df.columns:\n",
    "        raise KeyError(f\"{DATE_COL} not found.\")\n",
    "    df[DATE_COL] = pd.to_datetime(df[DATE_COL])\n",
    "\n",
    "    if target not in df.columns:\n",
    "        raise KeyError(f\"Target variable {target} not found.\")\n",
    "    print(f\"      - Target variable: {target}\")\n",
    "    \n",
    "    # Exclude only NaN in target column (keep other missing values)\n",
    "    before_len = len(df)\n",
    "    df = df.dropna(subset=[target]).copy()\n",
    "    after_len = len(df)\n",
    "    if before_len != after_len:\n",
    "        print(f\"      - Target variable NaN removed: {before_len:,} → {after_len:,} rows\")\n",
    "\n",
    "    # Clip target variable to non-negative integers\n",
    "    df[target] = np.maximum(pd.to_numeric(df[target], errors=\"coerce\").fillna(0).astype(\"Int64\"), 0).astype(np.int64)\n",
    "    \n",
    "    # Sort by time series\n",
    "    df = df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "    print(f\"      - Time series sorting completed: {df[DATE_COL].min()} ～ {df[DATE_COL].max()}\")\n",
    "    return df, target\n",
    "\n",
    "def time_split_by_date(df: pd.DataFrame, train_ratio: float = 0.8, date_col: str = DATE_COL) -> Tuple[pd.Timestamp, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Time series 8:2 split (strict split without crossing same dates)\"\"\"\n",
    "    if len(df) == 0:\n",
    "        return pd.NaT, np.array([], dtype=int), np.array([], dtype=int)\n",
    "\n",
    "    # Assume already sorted by time series\n",
    "    df_sorted = df.sort_values(date_col)\n",
    "    n = len(df_sorted)\n",
    "    \n",
    "    # Determine 80% position based on rows\n",
    "    cut_row = max(1, int(n * train_ratio)) - 1  # 0-index\n",
    "    raw_cutoff = df_sorted.iloc[cut_row][date_col]\n",
    "    cutoff_date = pd.to_datetime(raw_cutoff)\n",
    "    \n",
    "    print(f\"       - Cutoff date determined: {cutoff_date} (80% position based on row count)\")\n",
    "\n",
    "    # Split using <= / > to avoid crossing same dates\n",
    "    train_mask = df[date_col] <= cutoff_date\n",
    "    val_mask = df[date_col] > cutoff_date\n",
    "    \n",
    "    print(f\"        - Initial split: train={train_mask.sum():,} rows, val={val_mask.sum():,} rows\")\n",
    "\n",
    "    # Handle case when val is empty\n",
    "    if val_mask.sum() == 0:\n",
    "        print(f\"        - val is empty, lowering to previous unique date\")\n",
    "        uniq_dates = np.sort(df[date_col].unique())\n",
    "        pos = np.searchsorted(uniq_dates, cutoff_date, side=\"left\")\n",
    "        if pos > 0:\n",
    "            cutoff_date = uniq_dates[pos - 1]\n",
    "            train_mask = df[date_col] <= cutoff_date\n",
    "            val_mask = df[date_col] > cutoff_date\n",
    "            print(f\"        - After lowering: train={train_mask.sum():,} rows, val={val_mask.sum():,} rows\")\n",
    "        \n",
    "        # If val is still empty, set last date to val\n",
    "        if val_mask.sum() == 0:\n",
    "            print(f\"        - Setting last date to val\")\n",
    "            last_date = uniq_dates[-1]\n",
    "            train_mask = df[date_col] < last_date\n",
    "            val_mask = df[date_col] >= last_date\n",
    "            cutoff_date = last_date\n",
    "            print(f\"        - Final split: train={train_mask.sum():,} rows, val={val_mask.sum():,} rows\")\n",
    "\n",
    "    tr_idx = df.index[train_mask].to_numpy()\n",
    "    va_idx = df.index[val_mask].to_numpy()\n",
    "    \n",
    "    # Verify that same dates do not cross train/val\n",
    "    train_dates = set(df.loc[train_mask, date_col].unique())\n",
    "    val_dates = set(df.loc[val_mask, date_col].unique())\n",
    "    overlap = train_dates & val_dates\n",
    "    if overlap:\n",
    "        raise ValueError(f\"Same dates cross train/val: {overlap}\")\n",
    "    \n",
    "    print(f\"        - Split completed: cutoff_date={cutoff_date}, train={len(tr_idx):,} rows, val={len(va_idx):,} rows\")\n",
    "    return cutoff_date, tr_idx, va_idx\n",
    "\n",
    "def pick_feature_cols(df: pd.DataFrame, target_col: str) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"Extract feature columns\"\"\"\n",
    "    cols = []\n",
    "    ban_cols = set(BAN_COLS_COMMON) | {target_col}\n",
    "    \n",
    "    for c in df.columns:\n",
    "        if c in ban_cols:\n",
    "            continue\n",
    "        # Exclude prefixes that may cause future leakage\n",
    "        if any(c.startswith(p) for p in BAN_PREFIXES):\n",
    "            continue\n",
    "        # Exclude datetime columns\n",
    "        if np.issubdtype(df[c].dtype, np.datetime64):\n",
    "            continue\n",
    "        cols.append(c)\n",
    "    \n",
    "    # Numeric columns (excluding categorical integer columns)\n",
    "    num_cols = [c for c in cols if pd.api.types.is_numeric_dtype(df[c]) and c not in CAT_INT_COLS]\n",
    "    # Categorical columns (only predefined categorical integer columns)\n",
    "    cat_cols = [c for c in CAT_INT_COLS if c in df.columns]\n",
    "    \n",
    "    print(f\"        - Feature selection: numeric={len(num_cols)}, categorical={len(cat_cols)}, excluded={len(df.columns) - len(num_cols) - len(cat_cols) - len(ban_cols)}\")\n",
    "    return num_cols, cat_cols\n",
    "\n",
    "def make_3fold_80_20_indices(df: pd.DataFrame, date_col: str = DATE_COL) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"3-fold Time Series Split (divide into 3 equal parts based on sold_date, 8:2 split within each fold)\"\"\"\n",
    "    # Get and sort all sold_date data\n",
    "    df_sorted = df.sort_values(date_col).reset_index(drop=True)\n",
    "    unique_dates = df_sorted[date_col].unique()\n",
    "    n_dates = len(unique_dates)\n",
    "    \n",
    "    print(f\"        - Number of unique dates: {n_dates:,} days\")\n",
    "    \n",
    "    # Determine dates for 3-way division\n",
    "    date_1_3 = unique_dates[n_dates // 3]\n",
    "    date_2_3 = unique_dates[2 * n_dates // 3]\n",
    "    \n",
    "    print(f\"        - 3-way division dates: {date_1_3}, {date_2_3}\")\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    for k in range(3):\n",
    "        # Determine date range for each fold\n",
    "        if k == 0:\n",
    "            # Fold 1: First 1/3\n",
    "            fold_start_date = unique_dates[0]\n",
    "            fold_end_date = date_1_3\n",
    "        elif k == 1:\n",
    "            # Fold 2: Middle 1/3\n",
    "            fold_start_date = date_1_3\n",
    "            fold_end_date = date_2_3\n",
    "        else:\n",
    "            # Fold 3: Last 1/3\n",
    "            fold_start_date = date_2_3\n",
    "            fold_end_date = unique_dates[-1]\n",
    "        \n",
    "        # Get data within each fold\n",
    "        fold_mask = (df_sorted[date_col] >= fold_start_date) & (df_sorted[date_col] <= fold_end_date)\n",
    "        fold_df = df_sorted[fold_mask].reset_index(drop=True)\n",
    "        fold_dates = fold_df[date_col].unique()\n",
    "        n_fold_dates = len(fold_dates)\n",
    "        \n",
    "        # Determine cutoff date for 8:2 split within fold\n",
    "        train_end_date_idx = int(n_fold_dates * 0.8)\n",
    "        train_end_date = fold_dates[train_end_date_idx]\n",
    "        \n",
    "        # Get train/val indices\n",
    "        train_mask = fold_df[date_col] <= train_end_date\n",
    "        val_mask = fold_df[date_col] > train_end_date\n",
    "        \n",
    "        # Convert to original DataFrame indices\n",
    "        train_idx = fold_df[train_mask].index.to_numpy()\n",
    "        val_idx = fold_df[val_mask].index.to_numpy()\n",
    "        \n",
    "        print(f\"        - Fold {k+1}: Date range [{fold_start_date}～{fold_end_date}]\")\n",
    "        print(f\"          - train: {len(train_idx):,} rows (～{train_end_date}), val: {len(val_idx):,} rows\")\n",
    "        \n",
    "        folds.append((train_idx, val_idx))\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac65571d-4b5a-435d-b5e9-90747dfec0e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# General Functions for LightGBM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e3367-7d3a-43f8-99d6-647103c60cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_preprocess_for_lgb(df: pd.DataFrame, num_cols: List[str], cat_cols: List[str]) -> pd.DataFrame:\n",
    "    X = df[num_cols + cat_cols].copy()\n",
    "    for c in num_cols:\n",
    "        X[c] = X[c].astype(float).fillna(0.0)\n",
    "    for c in cat_cols:\n",
    "        X[c] = X[c].astype(\"Int64\").fillna(-1)\n",
    "    return X\n",
    "\n",
    "def lgb_train_eval(\n",
    "    X_tr: pd.DataFrame, y_tr: np.ndarray,\n",
    "    X_va: Optional[pd.DataFrame], y_va: Optional[np.ndarray],\n",
    "    cat_cols: List[str],\n",
    "    num_boost_round: int = LGB_NUM_BOOST_ROUND,\n",
    "    early_stopping_rounds: int = LGB_EARLY_STOP_ROUNDS\n",
    ") -> Tuple[lgb.Booster, np.ndarray, float]:\n",
    "    dtrain = lgb.Dataset(X_tr, label=y_tr, categorical_feature=cat_cols, free_raw_data=True)\n",
    "    valid_sets = [dtrain]; valid_names = [\"train\"]\n",
    "    callbacks = []\n",
    "    dvalid = None\n",
    "    if X_va is not None and y_va is not None:\n",
    "        dvalid = lgb.Dataset(X_va, label=y_va, categorical_feature=cat_cols, reference=dtrain, free_raw_data=True)\n",
    "        valid_sets = [dtrain, dvalid]; valid_names = [\"train\", \"valid\"]\n",
    "        callbacks = [lgb.early_stopping(early_stopping_rounds, verbose=False)]\n",
    "\n",
    "    params = dict(\n",
    "        objective=\"tweedie\", tweedie_variance_power=1.5,\n",
    "        learning_rate=0.05, num_leaves=64, min_data_in_leaf=100,\n",
    "        feature_fraction=0.9, bagging_fraction=0.9, bagging_freq=1,\n",
    "        lambda_l1=0.0, max_depth=-1, seed=RANDOM_SEED, verbose=-1,\n",
    "        metric=\"rmse\", first_metric_only=True, feature_pre_filter=False,\n",
    "    )\n",
    "\n",
    "    booster = lgb.train(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        valid_sets=valid_sets,\n",
    "        valid_names=valid_names,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    del dtrain\n",
    "    if dvalid is not None:\n",
    "        del dvalid\n",
    "    gc.collect()\n",
    "\n",
    "    if X_va is None or y_va is None:\n",
    "        return booster, np.array([]), np.nan\n",
    "\n",
    "    pred_va = booster.predict(X_va, num_iteration=booster.best_iteration)\n",
    "    rmse = float(np.sqrt(np.mean((y_va - pred_va) ** 2)))\n",
    "    return booster, pred_va, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e6e75d-091e-40fc-8d55-b3f5160df631",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LightGBM Steps 1 & 2 Training\n",
    "\n",
    "- Step 1 : Train using all features with data split into 3 folds to create **feature importance rankings**\n",
    "- Step 2 : Evaluate accuracy when training with **Top K** features using the feature importance rankings, and select the optimal number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339e7a0e-647c-47ec-aa77-60a3a139c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_fold_importances_raw(\n",
    "    df_train: pd.DataFrame, target_col: str,\n",
    "    num_cols: List[str], cat_cols: List[str],\n",
    "    folds: List[Tuple[np.ndarray, np.ndarray]],\n",
    "    out_dir: Path\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Calculate feature importance using only train data (prevent time series leakage)\"\"\"\n",
    "    print(f\"    Starting LightGBM feature importance calculation (train only, {len(folds)} folds)\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    all_imps = []\n",
    "    cols = num_cols + cat_cols\n",
    "    y_train = df_train[target_col].to_numpy()\n",
    "    print(f\"    - Total number of features: {len(cols)} (numeric:{len(num_cols)}, categorical:{len(cat_cols)})\")\n",
    "    print(f\"    - Train data: {len(df_train):,} rows\")\n",
    "\n",
    "    for i, (tr_idx, va_idx) in enumerate(folds, start=1):\n",
    "        print(f\"      Processing Fold {i}/{len(folds)}...\")\n",
    "        fdir = out_dir / f\"fold{i}\"\n",
    "        fdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Fold split within train data\n",
    "        X_tr = lgb_preprocess_for_lgb(df_train.iloc[tr_idx], num_cols, cat_cols)\n",
    "        X_va = lgb_preprocess_for_lgb(df_train.iloc[va_idx], num_cols, cat_cols)\n",
    "        y_tr = y_train[tr_idx]; y_va = y_train[va_idx]\n",
    "        print(f\"        - Training data: {len(X_tr):,} rows\")\n",
    "        print(f\"        - Validation data: {len(X_va):,} rows\")\n",
    "\n",
    "        booster, pred_va, rmse = lgb_train_eval(X_tr, y_tr, X_va, y_va, cat_cols)\n",
    "        save_pickle(booster, fdir / \"lgb_importance_model.pkl\")\n",
    "        \n",
    "        # Calculate R²\n",
    "        ss_res = np.sum((y_va - pred_va) ** 2)\n",
    "        ss_tot = np.sum((y_va - np.mean(y_va)) ** 2)\n",
    "        r2 = 1.0 - (ss_res / (ss_tot + 1e-9))\n",
    "        print(f\"        - Training completed: RMSE={rmse:.6f}, R²={r2:.6f}\")\n",
    "\n",
    "        imp = pd.DataFrame({\n",
    "            \"feature\": cols,\n",
    "            \"gain\": booster.feature_importance(importance_type=\"gain\"),\n",
    "            \"split\": booster.feature_importance(importance_type=\"split\"),\n",
    "            \"fold\": i,\n",
    "            \"rmse_val\": rmse\n",
    "        })\n",
    "        imp.sort_values([\"gain\", \"split\"], ascending=False).to_csv(fdir / \"feature_importance.csv\", index=False)\n",
    "        all_imps.append(imp)\n",
    "\n",
    "        del booster, X_tr, X_va, y_tr, y_va, imp\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"    Aggregating importance...\")\n",
    "    imp_cat = pd.concat(all_imps, axis=0, ignore_index=True)\n",
    "    avg = (imp_cat.groupby(\"feature\", as_index=False)\n",
    "                 .agg(gain_mean=(\"gain\",\"mean\"), split_mean=(\"split\",\"mean\")))\n",
    "    avg = avg.sort_values([\"gain_mean\", \"split_mean\"], ascending=False).reset_index(drop=True)\n",
    "    avg.to_csv(out_dir / \"feature_importance_avg.csv\", index=False)\n",
    "    print(f\"    - Importance aggregation completed: {len(avg)} features\")\n",
    "\n",
    "    del all_imps, imp_cat\n",
    "    gc.collect()\n",
    "    return avg\n",
    "\n",
    "def lgb_kgrid_cv_raw(\n",
    "    df_train: pd.DataFrame, target_col: str,\n",
    "    num_cols: List[str], cat_cols: List[str],\n",
    "    avg_importance: pd.DataFrame,\n",
    "    folds: List[Tuple[np.ndarray, np.ndarray]],\n",
    "    k_list: List[int], out_dir: Path\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"K-grid CV using only train data (prevent time series leakage)\"\"\"\n",
    "    print(f\"    Starting K-grid CV: K candidates={k_list} (train only)\")\n",
    "    rows = []\n",
    "    rank = avg_importance[\"feature\"].tolist()\n",
    "    y_train = df_train[target_col].to_numpy()\n",
    "    print(f\"    - Train data: {len(df_train):,} rows\")\n",
    "\n",
    "    for K in k_list:\n",
    "        print(f\"      Processing K={K}...\")\n",
    "        kdir = out_dir / f\"K{K}\"\n",
    "        kdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        topk = rank[:K]\n",
    "        sel_num = [c for c in topk if c in num_cols]\n",
    "        sel_cat = [c for c in topk if c in cat_cols]\n",
    "        print(f\"        - Selected features: {len(sel_num)} numeric + {len(sel_cat)} categorical = {len(topk)} total\")\n",
    "\n",
    "        fold_metrics = []\n",
    "        for i, (tr_idx, va_idx) in enumerate(folds, start=1):\n",
    "            fdir = kdir / f\"fold{i}\"\n",
    "            fdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Fold split within train data\n",
    "            X_tr = lgb_preprocess_for_lgb(df_train.iloc[tr_idx], sel_num, sel_cat)\n",
    "            y_tr = y_train[tr_idx]\n",
    "            X_va = lgb_preprocess_for_lgb(df_train.iloc[va_idx], sel_num, sel_cat)\n",
    "            y_va = y_train[va_idx]\n",
    "\n",
    "            booster, pred_va, rmse = lgb_train_eval(X_tr, y_tr, X_va, y_va, sel_cat)\n",
    "            save_pickle(booster, fdir / \"lgb_model.pkl\")\n",
    "            pd.DataFrame({\"y\": y_va, \"pred\": pred_va}).to_csv(fdir / \"pred_val.csv\", index=False)\n",
    "\n",
    "            # Calculate R²\n",
    "            ss_res = np.sum((y_va - pred_va) ** 2)\n",
    "            ss_tot = np.sum((y_va - np.mean(y_va)) ** 2)\n",
    "            r2 = 1.0 - (ss_res / (ss_tot + 1e-9))\n",
    "            \n",
    "            fold_metrics.append({\"fold\": i, \"RMSE_va\": rmse, \"R2_va\": r2})\n",
    "\n",
    "            del booster, X_tr, X_va, y_tr, y_va, pred_va\n",
    "            gc.collect()\n",
    "\n",
    "        dfm = pd.DataFrame(fold_metrics)\n",
    "        dfm.to_csv(kdir / \"fold_metrics.csv\", index=False)\n",
    "        rmse_mean = float(dfm[\"RMSE_va\"].mean())\n",
    "        rmse_std = float(dfm[\"RMSE_va\"].std(ddof=0))\n",
    "        r2_mean = float(dfm[\"R2_va\"].mean())\n",
    "        r2_std = float(dfm[\"R2_va\"].std(ddof=0))\n",
    "        row = {\"K\": K, \"RMSE_va_mean\": rmse_mean, \"RMSE_va_std\": rmse_std, \"R2_va_mean\": r2_mean, \"R2_va_std\": r2_std}\n",
    "        rows.append(row)\n",
    "        print(f\"        - RMSE: {rmse_mean:.6f} ± {rmse_std:.6f}, R²: {r2_mean:.6f} ± {r2_std:.6f}\")\n",
    "\n",
    "        del fold_metrics, dfm, topk, sel_num, sel_cat\n",
    "        gc.collect()\n",
    "\n",
    "    res = pd.DataFrame(rows).sort_values(\"RMSE_va_mean\").reset_index(drop=True)\n",
    "    res.to_csv(out_dir / \"kgrid_cv_results.csv\", index=False)\n",
    "    print(f\"    K-grid CV completed: Best K={res.iloc[0]['K']}, RMSE={res.iloc[0]['RMSE_va_mean']:.6f}, R²={res.iloc[0]['R2_va_mean']:.6f}\")\n",
    "    del rows, rank, y_train\n",
    "    gc.collect()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21739a91-88b4-4486-b917-ca9903e644e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Poisson Regression or Negative Binomial Regression Setup (Select and regress based on the distribution of the target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de499407-d523-48ee-b0ba-8f367ff22623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize(train: pd.DataFrame, valid: pd.DataFrame, cols: List[str],\n",
    "              lo_q=WINSOR_LO_Q, hi_q=WINSOR_HI_Q):\n",
    "    tr = train.copy(); va = valid.copy()\n",
    "    bounds = {}\n",
    "    for c in cols:\n",
    "        tr[c] = tr[c].astype(float)\n",
    "        va[c] = va[c].astype(float)\n",
    "        lo = np.nanquantile(tr[c], lo_q); hi = np.nanquantile(tr[c], hi_q)\n",
    "        tr[c] = np.clip(tr[c], lo, hi)\n",
    "        va[c] = np.clip(va[c], lo, hi)\n",
    "        bounds[c] = {\"lo\": float(lo), \"hi\": float(hi)}\n",
    "    return tr, va, bounds\n",
    "\n",
    "def asinh_scale(train: pd.DataFrame, valid: pd.DataFrame, cols: List[str], q=ASINH_Q):\n",
    "    tr = train.copy(); va = valid.copy(); scalers = {}\n",
    "    for c in cols:\n",
    "        base = np.asarray(tr[c].values, float)\n",
    "        cval = np.quantile(np.abs(base[~np.isnan(base)]), q) if base.size else 1.0\n",
    "        if not np.isfinite(cval) or cval <= 0: cval = 1.0\n",
    "        tr[c] = np.arcsinh(np.asarray(tr[c].values, float) / cval)\n",
    "        va[c] = np.arcsinh(np.asarray(va[c].values, float) / cval)\n",
    "        scalers[c] = float(cval)\n",
    "    return tr, va, scalers\n",
    "\n",
    "def improved_asinh_scale(train: pd.DataFrame, valid: pd.DataFrame, cols: List[str]):\n",
    "    \"\"\"Improved asinh scaling for NB (learned from train data)\"\"\"\n",
    "    tr = train.copy(); va = valid.copy(); scalers = {}\n",
    "    for c in cols:\n",
    "        base = np.asarray(tr[c].values, float)\n",
    "        \n",
    "        # Learn statistics from train data\n",
    "        mean_val = np.nanmean(base)\n",
    "        std_val = np.nanstd(base)\n",
    "        q95 = np.nanquantile(np.abs(base), 0.95)\n",
    "        \n",
    "        # Calculate more appropriate scaling parameters\n",
    "        if std_val > 0:\n",
    "            # Standardization + asinh transformation\n",
    "            scale_factor = max(std_val, q95 / 2.0)  # Larger of std and 95% quantile\n",
    "        else:\n",
    "            scale_factor = max(q95, 1.0)\n",
    "        \n",
    "        # Apply asinh transformation\n",
    "        tr[c] = np.arcsinh((base - mean_val) / scale_factor)\n",
    "        va[c] = np.arcsinh((np.asarray(va[c].values, float) - mean_val) / scale_factor)\n",
    "        \n",
    "        scalers[c] = {\n",
    "            \"mean\": float(mean_val),\n",
    "            \"std\": float(std_val),\n",
    "            \"scale_factor\": float(scale_factor),\n",
    "            \"q95\": float(q95)\n",
    "        }\n",
    "    return tr, va, scalers\n",
    "\n",
    "def prepare_int_cats_for_ohe(\n",
    "    train: pd.DataFrame, valid: pd.DataFrame, cat_int_cols: List[str], max_levels: int = 30\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, Dict[str, List[Any]]]:\n",
    "    tr = train.copy(); va = valid.copy(); kept: Dict[str, List[Any]] = {}\n",
    "    for c in cat_int_cols:\n",
    "        if c not in tr.columns:\n",
    "            continue\n",
    "        tr_s = tr[c].astype(\"Int64\").astype(\"string\").fillna(\"__MISSING__\")\n",
    "        va_s = va[c].astype(\"Int64\").astype(\"string\").fillna(\"__MISSING__\")\n",
    "        top = (tr_s.value_counts(dropna=False).sort_values(ascending=False).head(max_levels).index.tolist())\n",
    "        kept[c] = top; keep = set(top)\n",
    "        tr_s = tr_s.where(tr_s.isin(keep), \"__OTHER__\")\n",
    "        va_s = va_s.where(va_s.isin(keep), \"__OTHER__\")\n",
    "        cats = list(dict.fromkeys(top + [\"__OTHER__\", \"__MISSING__\"]))\n",
    "        tr[c] = pd.Categorical(tr_s, categories=cats)\n",
    "        va[c] = pd.Categorical(va_s, categories=cats)\n",
    "    return tr, va, kept\n",
    "\n",
    "def one_hot_align(train: pd.DataFrame, valid: pd.DataFrame, cat_cols: List[str], drop_first=True):\n",
    "    tr = pd.get_dummies(train, columns=cat_cols, drop_first=drop_first)\n",
    "    va = pd.get_dummies(valid, columns=cat_cols, drop_first=drop_first)\n",
    "    for c in tr.columns:\n",
    "        if c not in va.columns:\n",
    "            va[c] = 0\n",
    "    va = va[tr.columns]\n",
    "    tr = tr.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0).astype(float)\n",
    "    va = va.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0).astype(float)\n",
    "    return tr, va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce579187-49e9-4410-ba12-a5b2f11267a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_count_glm(X: pd.DataFrame, y: np.ndarray, alpha: float = 0.1, max_iter: int = 10000, tol: float = 1e-8):\n",
    "    \"\"\"\n",
    "    Poisson regression with Ridge (log link). Learner that returns non-negative, stable μ.\n",
    "    alpha is the strength of L2 regularization (default 0.1 for more flexibility).\n",
    "    \"\"\"\n",
    "    print(f\"          - Starting fit_count_glm: X.shape={X.shape}, y.shape={y.shape}, alpha={alpha}, max_iter={max_iter}, tol={tol}\")\n",
    "    \n",
    "    # More flexible parameter settings\n",
    "    model = PoissonRegressor(\n",
    "        alpha=alpha, \n",
    "        fit_intercept=True, \n",
    "        max_iter=max_iter, \n",
    "        tol=tol,\n",
    "        warm_start=False,\n",
    "        solver='lbfgs'  # More stable solver\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        model.fit(np.asarray(X, float), y.astype(float))\n",
    "        print(f\"          - fit_count_glm completed: converged={model.n_iter_}, loss={model.score(np.asarray(X, float), y.astype(float)):.6f}\")\n",
    "        \n",
    "        # Output parameter information\n",
    "        print(f\"          - Training parameters: alpha={alpha}, max_iter={max_iter}, tol={tol}\")\n",
    "        print(f\"          - Convergence status: converged in {model.n_iter_} iterations\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"          - fit_count_glm error: {e}\")\n",
    "        # Retry with more relaxed parameters\n",
    "        print(f\"          - Retrying: training with more relaxed parameters\")\n",
    "        model = PoissonRegressor(alpha=alpha*10, fit_intercept=True, max_iter=max_iter//2, tol=tol*10)\n",
    "        model.fit(np.asarray(X, float), y.astype(float))\n",
    "        print(f\"          - Retry completed: converged={model.n_iter_}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def poisson_grid_search(X: pd.DataFrame, y: np.ndarray, out_dir: Path) -> Tuple[Any, Dict[str, Any], float]:\n",
    "    \"\"\"Grid search for Poisson parameters\"\"\"\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.metrics import make_scorer, mean_squared_error\n",
    "    \n",
    "    print(f\"        - Starting Poisson grid search...\")\n",
    "    \n",
    "    # Grid search in a small region\n",
    "    param_grid = {\n",
    "        'alpha': [0.1,0.5,1.0],      # Regularization strength\n",
    "        'max_iter': [5000],      # Number of iterations\n",
    "        'tol': [1e-6]             # Convergence condition\n",
    "    }\n",
    "    \n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    results = []\n",
    "    \n",
    "    # Execute grid search\n",
    "    total_combinations = len(param_grid['alpha']) * len(param_grid['max_iter']) * len(param_grid['tol'])\n",
    "    print(f\"        - Total number of combinations: {total_combinations}\")\n",
    "    \n",
    "    for i, alpha in enumerate(param_grid['alpha']):\n",
    "        for j, max_iter in enumerate(param_grid['max_iter']):\n",
    "            for k, tol in enumerate(param_grid['tol']):\n",
    "                params = {'alpha': alpha, 'max_iter': max_iter, 'tol': tol}\n",
    "                print(f\"        - Trial {i*4 + j*2 + k + 1}/{total_combinations}: alpha={alpha}, max_iter={max_iter}, tol={tol}\")\n",
    "                \n",
    "                try:\n",
    "                    # Model training\n",
    "                    model = fit_count_glm(X, y, **params)\n",
    "                    \n",
    "                    # Evaluate with 3-fold CV (3-fold for small datasets)\n",
    "                    cv_scores = cross_val_score(\n",
    "                        model, X, y, \n",
    "                        cv=3, \n",
    "                        scoring=make_scorer(lambda y_true, y_pred: -mean_squared_error(y_true, y_pred)),\n",
    "                        n_jobs=1\n",
    "                    )\n",
    "                    mean_score = np.mean(cv_scores)\n",
    "                    \n",
    "                    print(f\"          - CV score: {mean_score:.6f} (±{np.std(cv_scores):.6f})\")\n",
    "                    \n",
    "                    results.append({\n",
    "                        'params': params,\n",
    "                        'cv_score': mean_score,\n",
    "                        'cv_std': np.std(cv_scores),\n",
    "                        'n_iter': model.n_iter_\n",
    "                    })\n",
    "                    \n",
    "                    # Update best score\n",
    "                    if mean_score > best_score:\n",
    "                        best_score = mean_score\n",
    "                        best_params = params\n",
    "                        best_model = model\n",
    "                        print(f\"          - Best score updated: {best_score:.6f}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"          - Error: {e}\")\n",
    "                    results.append({\n",
    "                        'params': params,\n",
    "                        'cv_score': -np.inf,\n",
    "                        'cv_std': 0.0,\n",
    "                        'n_iter': 0,\n",
    "                        'error': str(e)\n",
    "                    })\n",
    "    \n",
    "    # Save results\n",
    "    grid_results = {\n",
    "        'best_params': best_params,\n",
    "        'best_score': float(best_score),\n",
    "        'all_results': results,\n",
    "        'param_grid': param_grid\n",
    "    }\n",
    "    \n",
    "    # Verify directory exists and save file\n",
    "    try:\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        (out_dir / \"poisson_grid_search.json\").write_text(\n",
    "            json.dumps(grid_results, ensure_ascii=False, indent=2)\n",
    "        )\n",
    "        print(f\"        - Grid search results saved: {out_dir / 'poisson_grid_search.json'}\")\n",
    "    except Exception as e:\n",
    "        print(f\"        - Warning: Failed to save grid search results: {e}\")\n",
    "        # Continue processing even if file save fails\n",
    "    \n",
    "    print(f\"        - Grid search completed: Best parameters={best_params}, score={best_score:.6f}\")\n",
    "    \n",
    "    return best_model, best_params, best_score\n",
    "\n",
    "def glm_predict(model, X: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"PoissonRegressor prediction (mean μ). Always non-negative.\"\"\"\n",
    "    return np.asarray(model.predict(np.asarray(X, float)), float)\n",
    "\n",
    "def cap_mu(mu: np.ndarray, y_ref: np.ndarray, q: float = 0.999, mult: float = 2.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Upper limit control for predictions. Clip to q quantile × mult of training data as upper limit.\n",
    "    Physically prevents \"unrealistic\" outliers.\n",
    "    \"\"\"\n",
    "    cap = np.quantile(y_ref.astype(float), q) * mult\n",
    "    if not np.isfinite(cap) or cap <= 0:\n",
    "        return np.clip(mu, 0.0, None)\n",
    "    return np.clip(mu, 0.0, cap)\n",
    "\n",
    "# --- (Reference) Original NB model function ---\n",
    "def fit_nb(X: pd.DataFrame, y: np.ndarray):\n",
    "    X_np = np.asarray(X, dtype=float)\n",
    "    exog = sm.add_constant(X_np, has_constant=\"add\")\n",
    "    \n",
    "    # More stable initialization\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=HessianInversionWarning)\n",
    "        try:\n",
    "            # Initialize with simpler Poisson model\n",
    "            pois = PoisDM(y, exog).fit(method=\"lbfgs\", maxiter=100, disp=False)\n",
    "            beta0 = pois.params\n",
    "        except Exception:\n",
    "            # More conservative initialization\n",
    "            beta0 = np.zeros(exog.shape[1])\n",
    "            beta0[0] = np.log(np.mean(y) + 1e-6)  # Initialize intercept with log of mean\n",
    "    \n",
    "    # More conservative initialization of dispersion parameter\n",
    "    start_params = np.r_[beta0, 0.5]  # 0.1 → 0.5\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=HessianInversionWarning)\n",
    "        model = NegativeBinomial(y, exog)\n",
    "        # More iterations and more stable optimization\n",
    "        res = model.fit(method=\"lbfgs\", start_params=start_params, maxiter=1000, disp=False)\n",
    "    return model, res\n",
    "\n",
    "def nb_predict_with_se(res, X: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    X_np = np.asarray(X, dtype=float)\n",
    "    exog = sm.add_constant(X_np, has_constant=\"add\")\n",
    "    mu = np.asarray(res.predict(exog), float)\n",
    "    try:\n",
    "        cov = np.asarray(res.cov_params())\n",
    "        var_eta = np.einsum('ij,jk,ik->i', exog, cov, exog)\n",
    "        var_eta = np.clip(var_eta, 0.0, None)\n",
    "        se_mu = mu * np.sqrt(var_eta)  # Delta method\n",
    "    except Exception:\n",
    "        se_mu = np.full_like(mu, np.nan, dtype=float)\n",
    "    return mu, se_mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce78fddc-2888-44bb-979b-5cc0275e0da8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Perform Poisson or NB Regression for Final Model Training and Introduce Results as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db9ff4-1101-4c53-beb1-5629c2c816c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nb_features_for_val_from_train(\n",
    "    df_train: pd.DataFrame, df_val: pd.DataFrame, target_col: str,\n",
    "    selected_num_cols: List[str], selected_cat_cols: List[str]\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"Generate val features using NB model trained on train data (prevent time series leakage)\"\"\"\n",
    "    print(f\"    Starting val NB feature generation (using train-trained model)\")\n",
    "    \n",
    "    use_feats = selected_num_cols + selected_cat_cols\n",
    "    sel_num = [c for c in use_feats if c in selected_num_cols]\n",
    "    sel_cat = [c for c in use_feats if c in selected_cat_cols]\n",
    "    print(f\"    - Features used: {len(sel_num)} numeric + {len(sel_cat)} categorical = {len(use_feats)} total\")\n",
    "\n",
    "    # Preprocess train data\n",
    "    tr_df = df_train[sel_num + sel_cat].copy()\n",
    "    va_df = df_val[sel_num + sel_cat].copy()\n",
    "    \n",
    "    print(f\"    - Train data: {len(tr_df):,} rows\")\n",
    "    print(f\"    - Val data: {len(va_df):,} rows\")\n",
    "\n",
    "    # Preprocess numeric features (determine bounds from train statistics)\n",
    "    print(f\"    - Preprocessing numeric features...\")\n",
    "    for c in sel_num:\n",
    "        tr_df[c] = tr_df[c].astype(float).fillna(0.0)\n",
    "        va_df[c] = va_df[c].astype(float).fillna(0.0)\n",
    "    \n",
    "    # Preprocessing for NB: only mild winsorization (asinh scaling removed)\n",
    "    Tr_cont, Va_cont, bounds = winsorize(tr_df[sel_num], va_df[sel_num], sel_num, 5.0/100, 95.0/100)\n",
    "    # Remove asinh scaling and use as is\n",
    "    improved_scalers = {}\n",
    "    tr_df[sel_num] = Tr_cont; va_df[sel_num] = Va_cont\n",
    "\n",
    "    # OHE transformation for categorical features (fixed to train levels)\n",
    "    print(f\"    - OHE transforming categorical features...\")\n",
    "    tr_cat_ready, va_cat_ready, _ = prepare_int_cats_for_ohe(tr_df, va_df, sel_cat, max_levels=30)\n",
    "    X_tr, X_va = one_hot_align(tr_cat_ready, va_cat_ready, sel_cat, drop_first=True)\n",
    "    print(f\"    - Number of features after OHE: {X_tr.shape[1]}\")\n",
    "\n",
    "    # Train NB on entire train data\n",
    "    y_tr = df_train[target_col].to_numpy()\n",
    "    print(f\"    - Training Poisson(Ridge)...\")\n",
    "    model = fit_count_glm(X_tr, y_tr, alpha=1.0)\n",
    "\n",
    "    # Predict for val (mu only)\n",
    "    print(f\"    - Predicting for val...\")\n",
    "    mu_va = glm_predict(model, X_va)\n",
    "    mu_va = cap_mu(mu_va, y_tr, q=0.999, mult=2.0)\n",
    "    \n",
    "    # Calculate R² for val NB predictions\n",
    "    y_val = df_val[target_col].to_numpy()\n",
    "    ss_res = np.sum((y_val - mu_va) ** 2)\n",
    "    ss_tot = np.sum((y_val - np.mean(y_val)) ** 2)\n",
    "    r2 = 1.0 - (ss_res / (ss_tot + 1e-9))\n",
    "    \n",
    "    print(f\"    - Val NB prediction completed: mean prediction={np.mean(mu_va):.3f}, R²={r2:.6f}\")\n",
    "    print(f\"    - Actual value statistics: mean={np.mean(y_val):.3f}, min={np.min(y_val):.3f}, max={np.max(y_val):.3f}\")\n",
    "    print(f\"    - Prediction statistics: mean={np.mean(mu_va):.3f}, min={np.min(mu_va):.3f}, max={np.max(mu_va):.3f}\")\n",
    "\n",
    "    # Create val features (mu only)\n",
    "    nb_feat_val = pd.DataFrame({\"nb_mu\": mu_va})\n",
    "    \n",
    "    # Save preprocessing information\n",
    "    preproc_info = {\n",
    "        \"winsor_bounds\": bounds,\n",
    "        \"improved_scalers\": improved_scalers,\n",
    "        \"sel_num\": sel_num,\n",
    "        \"sel_cat\": sel_cat,\n",
    "        \"ohe_columns\": list(X_tr.columns)\n",
    "    }\n",
    "    \n",
    "    return nb_feat_val, preproc_info\n",
    "\n",
    "def build_nb_oof_features(\n",
    "    df_train: pd.DataFrame, target_col: str,\n",
    "    top_rank: List[str], num_cols: List[str], cat_cols: List[str],\n",
    "    folds: List[Tuple[np.ndarray, np.ndarray]],\n",
    "    out_dir: Path, nb_top: int = NB_TOP\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Generate NB OOF features using only train data (prevent time series leakage)\"\"\"\n",
    "    print(f\"    Starting Negative Binomial OOF feature generation (train only, top {nb_top} features)\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    use_feats = top_rank[:nb_top]\n",
    "    sel_num = [c for c in use_feats if c in num_cols]\n",
    "    sel_cat = [c for c in use_feats if c in cat_cols]\n",
    "    print(f\"    - Features used: {len(sel_num)} numeric + {len(sel_cat)} categorical = {len(use_feats)} total\")\n",
    "    print(f\"    - Train data: {len(df_train):,} rows\")\n",
    "\n",
    "    oof_mu = np.full(len(df_train), np.nan, dtype=float)\n",
    "    y_train = df_train[target_col].to_numpy()\n",
    "\n",
    "    for i, (tr_idx, va_idx) in enumerate(folds, start=1):\n",
    "        print(f\"      Processing NB Fold {i}/{len(folds)}...\")\n",
    "        fdir = out_dir / f\"fold{i}\"\n",
    "        fdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Fold split within train data\n",
    "        tr_df = df_train.iloc[tr_idx][sel_num + sel_cat].copy()\n",
    "        va_df = df_train.iloc[va_idx][sel_num + sel_cat].copy()\n",
    "        print(f\"        - Training data: {len(tr_df):,} rows\")\n",
    "        print(f\"        - Validation data: {len(va_df):,} rows\")\n",
    "\n",
    "        print(f\"        - Preprocessing numeric features...\")\n",
    "        for c in sel_num:\n",
    "            tr_df[c] = tr_df[c].astype(float).fillna(0.0)\n",
    "            va_df[c] = va_df[c].astype(float).fillna(0.0)\n",
    "        # Preprocessing for NB: only mild winsorization (asinh scaling removed)\n",
    "        Tr_cont, Va_cont, bounds = winsorize(tr_df[sel_num], va_df[sel_num], sel_num, 5.0/100, 95.0/100)\n",
    "        # Remove asinh scaling and use as is\n",
    "        improved_scalers = {}\n",
    "        tr_df[sel_num] = Tr_cont; va_df[sel_num] = Va_cont\n",
    "\n",
    "        print(f\"        - OHE transforming categorical features...\")\n",
    "        tr_cat_ready, va_cat_ready, _ = prepare_int_cats_for_ohe(tr_df, va_df, sel_cat, max_levels=30)\n",
    "        X_tr, X_va = one_hot_align(tr_cat_ready, va_cat_ready, sel_cat, drop_first=True)\n",
    "        print(f\"        - Number of features after OHE: {X_tr.shape[1]}\")\n",
    "\n",
    "        y_tr = y_train[tr_idx]; y_va = y_train[va_idx]\n",
    "        print(f\"        - Training Poisson(Ridge)... (train: {len(y_tr):,} rows, val: {len(y_va):,} rows)\")\n",
    "        print(f\"        - y_tr statistics: mean={np.mean(y_tr):.3f}, min={np.min(y_tr):.3f}, max={np.max(y_tr):.3f}\")\n",
    "        model = fit_count_glm(X_tr, y_tr, alpha=1.0)\n",
    "        print(f\"        - Poisson training completed\")\n",
    "        save_pickle(model, fdir / \"nb_model.pkl\")  # Keep filename for compatibility\n",
    "        (fdir / \"numeric_preproc.json\").write_text(\n",
    "            json.dumps({\"winsor_bounds\": bounds, \"improved_scalers\": improved_scalers,\n",
    "                        \"sel_num\": sel_num, \"sel_cat\": sel_cat}, ensure_ascii=False, indent=2)\n",
    "        )\n",
    "\n",
    "        print(f\"        - Predicting...\")\n",
    "        mu_va = glm_predict(model, X_va)\n",
    "        mu_va = cap_mu(mu_va, y_tr, q=0.999, mult=2.0)\n",
    "        se_va = np.full_like(mu_va, np.nan, dtype=float)  # Keep column for compatibility\n",
    "\n",
    "        oof_mu[va_idx] = mu_va\n",
    "\n",
    "        # Calculate R² for NB predictions\n",
    "        ss_res = np.sum((y_va - mu_va) ** 2)\n",
    "        ss_tot = np.sum((y_va - np.mean(y_va)) ** 2)\n",
    "        r2 = 1.0 - (ss_res / (ss_tot + 1e-9))\n",
    "\n",
    "        pd.DataFrame({\"y\": y_va, \"nb_mu\": mu_va, \"nb_se\": se_va}).to_csv(\n",
    "            fdir / \"nb_val_preds.csv\", index=False\n",
    "        )\n",
    "        print(f\"        - NB prediction completed: mean prediction={np.mean(mu_va):.3f}, R²={r2:.6f}\")\n",
    "        print(f\"        - Actual value statistics: mean={np.mean(y_va):.3f}, min={np.min(y_va):.3f}, max={np.max(y_va):.3f}\")\n",
    "        print(f\"        - Prediction statistics: mean={np.mean(mu_va):.3f}, min={np.min(mu_va):.3f}, max={np.max(mu_va):.3f}\")\n",
    "\n",
    "        print(f\"        - Fold {i} processing completed\")\n",
    "        del tr_df, va_df, Tr_cont, Va_cont, X_tr, X_va, y_tr, y_va, model, mu_va, se_va\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"    Aggregating NB OOF features...\")\n",
    "    nb_feat = pd.DataFrame({\"nb_mu\": oof_mu})\n",
    "    nb_feat.to_csv(out_dir / \"nb_oof_features.csv\", index=False)\n",
    "    print(f\"    - NB feature generation completed: {len(nb_feat.columns)} features\")\n",
    "\n",
    "    del oof_mu, y_train\n",
    "    gc.collect()\n",
    "    return nb_feat\n",
    "\n",
    "def build_poisson_features_full_data(\n",
    "    df_train: pd.DataFrame, df_val: pd.DataFrame, target_col: str,\n",
    "    selected_num_cols: List[str], selected_cat_cols: List[str], out_dir: Path\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"Train Poisson using only train data → apply inference to both train/val\"\"\"\n",
    "    print(f\"    - Starting Poisson training with train data only (top {len(selected_num_cols + selected_cat_cols)} features)\")\n",
    "    \n",
    "    # Prepare features using only train data\n",
    "    tr_df = df_train[selected_num_cols + selected_cat_cols].copy()\n",
    "    va_df = df_val[selected_num_cols + selected_cat_cols].copy()\n",
    "    print(f\"    - Features used: {len(selected_num_cols)} numeric + {len(selected_cat_cols)} categorical\")\n",
    "    print(f\"    - Train data: {len(tr_df):,} rows, val data: {len(va_df):,} rows\")\n",
    "    \n",
    "    # Preprocess numeric features (determine bounds from train statistics)\n",
    "    print(f\"    - Preprocessing numeric features...\")\n",
    "    for c in selected_num_cols:\n",
    "        tr_df[c] = tr_df[c].astype(float).fillna(0.0)\n",
    "        va_df[c] = va_df[c].astype(float).fillna(0.0)\n",
    "    \n",
    "    # Mild winsorization (determine bounds from train statistics)\n",
    "    Tr_cont, Va_cont, bounds = winsorize(tr_df[selected_num_cols], va_df[selected_num_cols], selected_num_cols, 5.0/100, 95.0/100)\n",
    "    \n",
    "    # Scale numeric features (standardize using train statistics)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    Tr_cont_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(Tr_cont), \n",
    "        columns=Tr_cont.columns, \n",
    "        index=Tr_cont.index\n",
    "    )\n",
    "    Va_cont_scaled = pd.DataFrame(\n",
    "        scaler.transform(Va_cont), \n",
    "        columns=Va_cont.columns, \n",
    "        index=Va_cont.index\n",
    "    )\n",
    "    \n",
    "    tr_df[selected_num_cols] = Tr_cont_scaled\n",
    "    va_df[selected_num_cols] = Va_cont_scaled\n",
    "    \n",
    "    # Check statistics after scaling\n",
    "    print(f\"    - Statistics after scaling: train mean={np.mean(Tr_cont_scaled.values):.3f}, val mean={np.mean(Va_cont_scaled.values):.3f}\")\n",
    "    print(f\"    - Range after scaling: train[{np.min(Tr_cont_scaled.values):.3f}, {np.max(Tr_cont_scaled.values):.3f}], val[{np.min(Va_cont_scaled.values):.3f}, {np.max(Va_cont_scaled.values):.3f}]\")\n",
    "    \n",
    "    # OHE transformation for categorical features (fixed to train levels)\n",
    "    print(f\"    - OHE transforming categorical features...\")\n",
    "    tr_cat_ready, va_cat_ready, _ = prepare_int_cats_for_ohe(tr_df, va_df, selected_cat_cols, max_levels=30)\n",
    "    X_tr, X_va = one_hot_align(tr_cat_ready, va_cat_ready, selected_cat_cols, drop_first=True)\n",
    "    print(f\"    - Number of features after OHE: {X_tr.shape[1]}\")\n",
    "    \n",
    "    # Train Poisson using only train data\n",
    "    y_tr = df_train[target_col].to_numpy()\n",
    "    print(f\"    - Training Poisson(Ridge)... (train only: {len(y_tr):,} rows)\")\n",
    "    print(f\"    - y statistics: mean={np.mean(y_tr):.3f}, min={np.min(y_tr):.3f}, max={np.max(y_tr):.3f}\")\n",
    "    \n",
    "    # Parameter grid search\n",
    "    model, best_params, best_score = poisson_grid_search(X_tr, y_tr, out_dir)\n",
    "    print(f\"    - Poisson training completed (best score: {best_score:.6f})\")\n",
    "    \n",
    "    # Save model and parameters\n",
    "    save_pickle(model, out_dir / \"poisson_model.pkl\")\n",
    "    \n",
    "    # Save parameter information\n",
    "    model_info = {\n",
    "        \"poisson_params\": best_params,\n",
    "        \"best_score\": float(best_score),\n",
    "        \"n_iter\": int(model.n_iter_),\n",
    "        \"n_features\": int(X_tr.shape[1]),\n",
    "        \"train_size\": int(len(y_tr)),\n",
    "        \"converged\": bool(model.n_iter_ < best_params[\"max_iter\"])\n",
    "    }\n",
    "    try:\n",
    "        (out_dir / \"poisson_model_info.json\").write_text(\n",
    "            json.dumps(model_info, ensure_ascii=False, indent=2)\n",
    "        )\n",
    "        print(f\"    - Model information saved: {out_dir / 'poisson_model_info.json'}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    - Warning: Failed to save model information: {e}\")\n",
    "    \n",
    "    # Apply inference to both train/val\n",
    "    print(f\"    - Predicting for train... ({len(X_tr):,} rows)\")\n",
    "    mu_train = glm_predict(model, X_tr)\n",
    "    mu_train = cap_mu(mu_train, y_tr, q=0.999, mult=2.0)\n",
    "    \n",
    "    print(f\"    - Predicting for val... ({len(X_va):,} rows)\")\n",
    "    mu_val = glm_predict(model, X_va)\n",
    "    mu_val = cap_mu(mu_val, y_tr, q=0.999, mult=2.0)  # Clip using train statistics\n",
    "    \n",
    "    # Create features\n",
    "    nb_feats_train = pd.DataFrame({\"nb_mu\": mu_train})\n",
    "    nb_feats_val = pd.DataFrame({\"nb_mu\": mu_val})\n",
    "    \n",
    "    # Calculate R²\n",
    "    y_val = df_val[target_col].to_numpy()\n",
    "    \n",
    "    ss_res_train = np.sum((y_tr - mu_train) ** 2)\n",
    "    ss_tot_train = np.sum((y_tr - np.mean(y_tr)) ** 2)\n",
    "    r2_train = 1.0 - (ss_res_train / (ss_tot_train + 1e-9))\n",
    "    \n",
    "    ss_res_val = np.sum((y_val - mu_val) ** 2)\n",
    "    ss_tot_val = np.sum((y_val - np.mean(y_val)) ** 2)\n",
    "    r2_val = 1.0 - (ss_res_val / (ss_tot_val + 1e-9))\n",
    "    \n",
    "    print(f\"    - train R²: {r2_train:.6f}, val R²: {r2_val:.6f}\")\n",
    "    print(f\"    - train prediction statistics: mean={np.mean(mu_train):.3f}, min={np.min(mu_train):.3f}, max={np.max(mu_train):.3f}\")\n",
    "    print(f\"    - val prediction statistics: mean={np.mean(mu_val):.3f}, min={np.min(mu_val):.3f}, max={np.max(mu_val):.3f}\")\n",
    "    \n",
    "    # Check prediction diversity\n",
    "    train_unique = len(np.unique(mu_train))\n",
    "    val_unique = len(np.unique(mu_val))\n",
    "    print(f\"    - Prediction diversity: train={train_unique:,} types, val={val_unique:,} types\")\n",
    "    \n",
    "    if train_unique < 10 or val_unique < 10:\n",
    "        print(f\"    Warning: Prediction diversity may be low\")\n",
    "        print(f\"    - Consider adjusting parameters: alpha={best_params['alpha']}\")\n",
    "    \n",
    "    # Preprocessing information\n",
    "    preproc_info = {\n",
    "        \"winsor_bounds\": bounds,\n",
    "        \"scaler_mean\": scaler.mean_.tolist(),\n",
    "        \"scaler_scale\": scaler.scale_.tolist(),\n",
    "        \"selected_num\": selected_num_cols,\n",
    "        \"selected_cat\": selected_cat_cols,\n",
    "        \"ohe_columns\": list(X_tr.columns),\n",
    "        \"poisson_params\": best_params,\n",
    "        \"model_info\": model_info,\n",
    "        \"r2_train\": float(r2_train),\n",
    "        \"r2_val\": float(r2_val)\n",
    "    }\n",
    "    \n",
    "    return nb_feats_train, nb_feats_val, preproc_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b02f03-caaa-4015-b786-05fb0082fe95",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Final LightGBM Training (Step 3)\n",
    "- Step 3 : Train LightGBM using K+1 features (K features selected in Step 2 + output values from Poisson or NB regression)\n",
    "           (No CV, split all period data into 8:2 (train/val) for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311db3aa-644d-4585-a2f4-2a651e1a5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_with_nbfeatures_fulltrain(\n",
    "    df_train: pd.DataFrame, df_val: pd.DataFrame, target_col: str,\n",
    "    avg_importance: pd.DataFrame,\n",
    "    nb_feats_train: pd.DataFrame, nb_feats_val: pd.DataFrame,\n",
    "    num_cols: List[str], cat_cols: List[str],\n",
    "    best_K: int, out_dir: Path\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Final LightGBM with train training → val prediction (prevent time series leakage)\"\"\"\n",
    "    print(f\"    Starting final LightGBM training (K={best_K})\")\n",
    "    rank = avg_importance[\"feature\"].tolist()\n",
    "    base_feats = rank[:best_K]\n",
    "    base_num = [c for c in base_feats if c in num_cols]\n",
    "    base_cat = [c for c in base_feats if c in cat_cols]\n",
    "    print(f\"    - Base features: {len(base_num)} numeric + {len(base_cat)} categorical\")\n",
    "\n",
    "    final_num = base_num + [\"nb_mu\"]\n",
    "    final_cat = base_cat\n",
    "    print(f\"    - Final features: {len(final_num)} numeric + {len(final_cat)} categorical = {len(final_num + final_cat)} total\")\n",
    "\n",
    "    kdir = out_dir / f\"final_full_with_nb_K{best_K}\"\n",
    "    kdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Training on train data\n",
    "    print(f\"    - Preparing train data...\")\n",
    "    df_train_aug = df_train[base_num + base_cat].copy().reset_index(drop=True)\n",
    "    df_train_aug = pd.concat([df_train_aug, nb_feats_train.reset_index(drop=True)], axis=1)\n",
    "    print(f\"    - Number of features after train concatenation: {len(df_train_aug.columns)}\")\n",
    "\n",
    "    # Prepare val data\n",
    "    print(f\"    - Preparing val data...\")\n",
    "    df_val_aug = df_val[base_num + base_cat].copy().reset_index(drop=True)\n",
    "    df_val_aug = pd.concat([df_val_aug, nb_feats_val.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    print(f\"    - Preprocessing train...\")\n",
    "    X_train = lgb_preprocess_for_lgb(df_train_aug, final_num, final_cat)\n",
    "    y_train = df_train[target_col].to_numpy()\n",
    "    print(f\"    - Train training data: {len(X_train):,} rows × {X_train.shape[1]} features\")\n",
    "\n",
    "    print(f\"    - Preprocessing val...\")\n",
    "    X_val = lgb_preprocess_for_lgb(df_val_aug, final_num, final_cat)\n",
    "    y_val = df_val[target_col].to_numpy()\n",
    "    print(f\"    - Val prediction data: {len(X_val):,} rows × {X_val.shape[1]} features\")\n",
    "\n",
    "    print(f\"    - Training on train...\")\n",
    "    booster_full, _, _ = lgb_train_eval(X_train, y_train, X_val, y_val, final_cat)\n",
    "    save_pickle(booster_full, kdir / \"lgb_model_full.pkl\")\n",
    "\n",
    "    print(f\"    - Predicting on val...\")\n",
    "    pred_val = booster_full.predict(X_val, num_iteration=booster_full.best_iteration)\n",
    "    \n",
    "    # Save prediction results\n",
    "    pd.DataFrame({\"y_val\": y_val, \"yhat_val\": pred_val}).to_csv(\n",
    "        kdir / \"val_predictions.csv\", index=False\n",
    "    )\n",
    "\n",
    "    # Calculate R² for final training\n",
    "    ss_res = np.sum((y_val - pred_val) ** 2)\n",
    "    ss_tot = np.sum((y_val - np.mean(y_val)) ** 2)\n",
    "    val_r2 = 1.0 - (ss_res / (ss_tot + 1e-9))\n",
    "    \n",
    "    summary = {\n",
    "        \"final_features\": {\"numeric\": final_num, \"categorical\": final_cat},\n",
    "        \"n_train\": int(len(X_train)),\n",
    "        \"n_val\": int(len(X_val)),\n",
    "        \"best_K\": int(best_K),\n",
    "        \"train_only\": True,\n",
    "        \"val_rmse\": float(np.sqrt(np.mean((y_val - pred_val) ** 2))),\n",
    "        \"val_r2\": val_r2\n",
    "    }\n",
    "    (kdir / \"summary.json\").write_text(json.dumps(summary, ensure_ascii=False, indent=2))\n",
    "    print(f\"    - Final model training completed: train={len(X_train):,}, val={len(X_val):,}, val_RMSE={summary['val_rmse']:.6f}, val_R²={summary['val_r2']:.6f}\")\n",
    "\n",
    "    del df_train_aug, df_val_aug, X_train, X_val, y_train, y_val, pred_val, booster_full\n",
    "    gc.collect()\n",
    "\n",
    "    return {\"summary\": summary, \"model_path\": str((kdir / \"lgb_model_full.pkl\").resolve())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5f060a-c48a-4b92-a0cd-9a1859b48656",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Training Pipeline Setup (Configure flow of functions above) and Evaluation Function Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be46e0-6899-4ced-b742-e751768a613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_task_df_and_splitinfo(task: str) -> Tuple[pd.DataFrame, str, int, int, pd.Timestamp]:\n",
    "    \"\"\"Return data loading and time series split information\"\"\"\n",
    "    df, target = load_src_df(task)\n",
    "    cutoff_date, tr_idx, va_idx = time_split_by_date(df, train_ratio=0.8, date_col=DATE_COL)\n",
    "    n_train, n_val = len(tr_idx), len(va_idx)\n",
    "    return df, target, n_train, n_val, cutoff_date\n",
    "\n",
    "def get_train_val_split(df_all: pd.DataFrame, cutoff_date: pd.Timestamp) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Split train/val from all data (prevent time series leakage)\"\"\"\n",
    "    train_mask = df_all[DATE_COL] <= cutoff_date\n",
    "    val_mask = df_all[DATE_COL] > cutoff_date\n",
    "    \n",
    "    df_train = df_all[train_mask].copy().reset_index(drop=True)\n",
    "    df_val = df_all[val_mask].copy().reset_index(drop=True)\n",
    "    \n",
    "    print(f\"        - train/val split: train={len(df_train):,} rows, val={len(df_val):,} rows\")\n",
    "    return df_train, df_val\n",
    "\n",
    "def run_pipeline_for_task(task: str):\n",
    "    print(f\"  Creating output directory for task '{task}'...\")\n",
    "    out_dir = ROOT_OUT_DIR / task\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\" Loading data & time series splitting...\")\n",
    "    df_all, target_col, n_train, n_val, cutoff_date = load_task_df_and_splitinfo(task)\n",
    "    print(f\"    - Total data count: {len(df_all):,}\")\n",
    "    print(f\"    - Target variable: {target_col}\")\n",
    "    print(f\"    - Training data count: {n_train:,} (80%)\")\n",
    "    print(f\"    - Validation data count: {n_val:,} (20%)\")\n",
    "    print(f\"    - Split cutoff date: {cutoff_date}\")\n",
    "\n",
    "    (out_dir / \"basic_info.json\").write_text(json.dumps({\n",
    "        \"task\": task, \"target\": target_col,\n",
    "        \"n_all\": int(len(df_all)), \"n_train_time80\": n_train, \"n_val_time20\": n_val,\n",
    "        \"cutoff_date\": str(cutoff_date)\n",
    "    }, ensure_ascii=False, indent=2))\n",
    "\n",
    "    print(f\" Selecting features...\")\n",
    "    num_all, cat_all = pick_feature_cols(df_all, target_col)\n",
    "    print(f\"    - Number of numeric features: {len(num_all)}\")\n",
    "    print(f\"    - Number of categorical features: {len(cat_all)}\")\n",
    "\n",
    "    # Split train/val\n",
    "    df_train, df_val = get_train_val_split(df_all, cutoff_date)\n",
    "    \n",
    "    print(f\" Setting up 3-fold CV...\")\n",
    "    # 3-fold CV within train data (based on sold_date)\n",
    "    folds_train = make_3fold_80_20_indices(df_train, date_col=DATE_COL)\n",
    "    (out_dir / \"folds.json\").write_text(json.dumps(\n",
    "        [{\"fold\": i+1, \"n_train\": int(len(tr)), \"n_val\": int(len(va))} for i, (tr, va) in enumerate(folds_train)],\n",
    "        ensure_ascii=False, indent=2)\n",
    "    )\n",
    "    print(f\"    - Fold setup completed: {len(folds_train)} folds\")\n",
    "\n",
    "    print(f\"  Step 1/4: Calculating LightGBM feature importance...\")\n",
    "    imp_dir = out_dir / \"importance_cv\"\n",
    "    avg_imp = lgb_fold_importances_raw(df_train, target_col, num_all, cat_all, folds_train, imp_dir)\n",
    "    print(f\"    - Importance calculation completed: {len(avg_imp)} features\")\n",
    "\n",
    "    print(f\"  Step 2/4: Running K-grid CV...\")\n",
    "    kcv_dir = out_dir / \"kgrid_lgb_cv\"\n",
    "    kres = lgb_kgrid_cv_raw(df_train, target_col, num_all, cat_all, avg_imp, folds_train, K_CANDIDATES, kcv_dir)\n",
    "    best_row = kres.iloc[0].to_dict()\n",
    "    best_K = int(best_row[\"K\"])\n",
    "    (out_dir / \"best_k.json\").write_text(json.dumps(best_row, ensure_ascii=False, indent=2))\n",
    "    print(f\"    - Best K: {best_K}\")\n",
    "    print(f\"    - Best RMSE: {best_row['RMSE_va_mean']:.6f}\")\n",
    "\n",
    "    print(f\"  Step 3/4: Generating Poisson features...\")\n",
    "    nb_dir = out_dir / \"nb_oof\"\n",
    "    \n",
    "    # Train Poisson model with all data combined\n",
    "    selected_features = avg_imp[\"feature\"].tolist()[:NB_TOP]\n",
    "    selected_num = [c for c in selected_features if c in num_all]\n",
    "    selected_cat = [c for c in selected_features if c in cat_all]\n",
    "    \n",
    "    nb_feats_train, nb_feats_val, nb_preproc_info = build_poisson_features_full_data(\n",
    "        df_train, df_val, target_col, selected_num, selected_cat, nb_dir\n",
    "    )\n",
    "    print(f\"    - train Poisson feature generation completed: {len(nb_feats_train.columns)} features\")\n",
    "    print(f\"    - val Poisson feature generation completed: {len(nb_feats_val.columns)} features\")\n",
    "    \n",
    "    # Save preprocessing information\n",
    "    (nb_dir / \"preproc_info.json\").write_text(\n",
    "        json.dumps(nb_preproc_info, ensure_ascii=False, indent=2)\n",
    "    )\n",
    "\n",
    "    print(f\"  Step 4/4: Final LightGBM training...\")\n",
    "    final = lgb_with_nbfeatures_fulltrain(df_train, df_val, target_col, avg_imp, nb_feats_train, nb_feats_val, num_all, cat_all, best_K, out_dir)\n",
    "    (out_dir / \"final_summary.json\").write_text(json.dumps(final, ensure_ascii=False, indent=2))\n",
    "    print(f\"    - Final model training completed\")\n",
    "\n",
    "    (out_dir / \"time_split.json\").write_text(json.dumps({\n",
    "        \"n_train\": n_train, \"n_val\": n_val, \"cutoff_date\": str(cutoff_date)\n",
    "    }, ensure_ascii=False, indent=2))\n",
    "\n",
    "    print(f\"  Task '{task}' completed: Best K={best_K}, RMSE_va_mean={best_row['RMSE_va_mean']:.6f}\")\n",
    "    print(f\"  Output location: {out_dir.resolve()}\")\n",
    "\n",
    "    # Free memory after each training step\n",
    "    print(f\"  Freeing memory...\")\n",
    "    to_delete = [df_all, df_train, df_val, folds_train, avg_imp, kres, best_row, nb_feats_train, nb_feats_val, final, num_all, cat_all]\n",
    "    for obj in to_delete:\n",
    "        try: del obj\n",
    "        except Exception: pass\n",
    "    gc.collect()\n",
    "    print(f\"  Memory freed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70993d5-28d4-458c-8f3b-1a45795b0bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_final_feature_spec(task_dir: Path) -> Tuple[List[str], List[str], str]:\n",
    "    cand = sorted(task_dir.glob(\"final_full_with_nb_K*/summary.json\"))\n",
    "    if not cand:\n",
    "        raise FileNotFoundError(f\"No final summary.json under {task_dir}\")\n",
    "    summ_path = cand[0]\n",
    "    with open(summ_path, \"r\") as f:\n",
    "        summ = json.load(f)\n",
    "    feats = summ[\"final_features\"]\n",
    "    final_num = feats[\"numeric\"]\n",
    "    final_cat = feats[\"categorical\"]\n",
    "    model_path = str(summ_path.parent.joinpath(\"lgb_model_full.pkl\"))\n",
    "    return final_num, final_cat, model_path\n",
    "\n",
    "def load_time_split_counts(task: str) -> Tuple[int, int, pd.Timestamp]:\n",
    "    \"\"\"Load time series split information from training time\"\"\"\n",
    "    task_dir = ROOT_OUT_DIR / task\n",
    "    sp = task_dir / \"time_split.json\"\n",
    "    if sp.exists():\n",
    "        js = json.loads(sp.read_text())\n",
    "        return int(js[\"n_train\"]), int(js[\"n_val\"]), pd.to_datetime(js[\"cutoff_date\"])\n",
    "    df, _ = load_src_df(task)\n",
    "    cutoff, tr, va = time_split_by_date(df, 0.8, DATE_COL)\n",
    "    return len(tr), len(va), cutoff\n",
    "\n",
    "def build_X_for_inference(df_base: pd.DataFrame, nb_val: pd.DataFrame,\n",
    "                          final_num: List[str], final_cat: List[str]) -> pd.DataFrame:\n",
    "    base_num = [c for c in final_num if c not in (\"nb_mu\")]\n",
    "    X_num = df_base.reindex(columns=base_num, fill_value=0.0).copy()\n",
    "    nb_cols = [\"nb_mu\"]\n",
    "    for c in nb_cols:\n",
    "        if c not in nb_val.columns:\n",
    "            raise KeyError(f\"nb features missing: {c}\")\n",
    "    X_nb = nb_val[nb_cols].copy()\n",
    "    X_cat = df_base.reindex(columns=final_cat, fill_value=-1).copy()\n",
    "    X_all = pd.concat([X_num, X_nb, X_cat], axis=1)\n",
    "    X_all = lgb_preprocess_for_lgb(X_all, final_num, final_cat)\n",
    "    assert list(X_all.columns) == (final_num + final_cat), \"Column order mismatch\"\n",
    "    return X_all\n",
    "\n",
    "def load_nb_features_for_val(task_dir: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load val NB features\"\"\"\n",
    "    # Load val NB features directly\n",
    "    val_pred_path = task_dir / \"final_full_with_nb_K*\" / \"val_predictions.csv\"\n",
    "    val_pred_candidates = list(task_dir.glob(\"final_full_with_nb_K*/val_predictions.csv\"))\n",
    "    \n",
    "    if not val_pred_candidates:\n",
    "        raise FileNotFoundError(f\"No val predictions found in {task_dir}\")\n",
    "    \n",
    "    val_pred_path = val_pred_candidates[0]\n",
    "    val_pred_df = pd.read_csv(val_pred_path)\n",
    "    \n",
    "    # Reconstruct NB features (from val predictions)\n",
    "    nb_val = pd.DataFrame({\"nb_mu\": val_pred_df[\"yhat_val\"]})\n",
    "    return nb_val\n",
    "\n",
    "def evaluate_single_task_val(task: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Evaluate single task on validation data (prevent time series leakage)\"\"\"\n",
    "    # Get val data with same split as training time\n",
    "    df_all, target_col = load_src_df(task)\n",
    "    _, _, cutoff_date = load_time_split_counts(task)\n",
    "    df_all = df_all.sort_values(DATE_COL).reset_index(drop=True)\n",
    "    val_mask = df_all[DATE_COL] > cutoff_date\n",
    "    y_val = df_all.loc[val_mask, target_col].to_numpy()\n",
    "\n",
    "    task_dir = ROOT_OUT_DIR / task\n",
    "    final_num, final_cat, model_path = load_final_feature_spec(task_dir)\n",
    "\n",
    "    # Load val NB features\n",
    "    nb_val = load_nb_features_for_val(task_dir)\n",
    "\n",
    "    # Prepare base features\n",
    "    use_base_cols = [c for c in (final_num + final_cat) if c not in (\"nb_mu\")]\n",
    "    df_val_base = df_all.loc[val_mask, use_base_cols].reindex(columns=use_base_cols, fill_value=0).reset_index(drop=True)\n",
    "\n",
    "    # Build inference features\n",
    "    X_val = build_X_for_inference(df_val_base, nb_val, final_num, final_cat)\n",
    "\n",
    "    # Predict with trained model\n",
    "    booster: lgb.Booster = pickle.load(open(model_path, \"rb\"))\n",
    "    yhat = booster.predict(X_val, num_iteration=booster.best_iteration)\n",
    "\n",
    "    # Save evaluation results\n",
    "    (task_dir / \"eval\").mkdir(parents=True, exist_ok=True)\n",
    "    pd.DataFrame({\"y_val\": y_val, \"yhat\": yhat}).to_csv(task_dir / \"eval\" / \"val_predictions.csv\", index=False)\n",
    "\n",
    "    return y_val, yhat\n",
    "\n",
    "def evaluate_sum_task_fixed():\n",
    "    y_val, yhat = evaluate_single_task_val(\"sum\")\n",
    "    return y_val, yhat, None\n",
    "\n",
    "def evaluate_horizon_sum_vs_sumval_fixed():\n",
    "    \"\"\"Compare sum of h1-h26 with sum validation data\"\"\"\n",
    "    df_sum, _ = load_src_df(\"sum\")\n",
    "    _, _, cutoff_date = load_time_split_counts(\"sum\")\n",
    "    df_sum = df_sum.sort_values(DATE_COL).reset_index(drop=True)\n",
    "    y_true_sum = df_sum.loc[df_sum[DATE_COL] > cutoff_date, SUM_TARGET].to_numpy()\n",
    "\n",
    "    preds = []\n",
    "    for N in range(1, 27):\n",
    "        task = f\"h{str(N).zfill(2)}\"\n",
    "        _, yhat_h = evaluate_single_task_val(task)\n",
    "        preds.append(yhat_h)\n",
    "\n",
    "    yhat_sum = np.sum(np.vstack(preds), axis=0)\n",
    "    return y_true_sum, yhat_sum\n",
    "\n",
    "def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"Calculate evaluation metrics\"\"\"\n",
    "    y_true = np.asarray(y_true, float)\n",
    "    y_pred = np.asarray(y_pred, float)\n",
    "    eps = 1e-9\n",
    "    rmse = float(np.sqrt(np.mean((y_pred - y_true) ** 2)))\n",
    "    mae = float(np.mean(np.abs(y_pred - y_true)))\n",
    "    smape = float(np.mean(2.0 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true) + eps)))\n",
    "    ss_res = float(np.sum((y_true - y_pred) ** 2))\n",
    "    ss_tot = float(np.sum((y_true - np.mean(y_true)) ** 2) + eps)\n",
    "    r2 = float(1.0 - ss_res / ss_tot)\n",
    "    bias = float(np.mean(y_pred - y_true))\n",
    "    return {\n",
    "        \"n_val\": int(y_true.size),\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"smape\": smape,\n",
    "        \"r2\": r2,\n",
    "        \"bias_mean\": bias,\n",
    "        \"sum_true\": float(np.sum(y_true)),\n",
    "        \"sum_pred\": float(np.sum(y_pred)),\n",
    "        \"sum_diff\": float(np.sum(y_pred) - np.sum(y_true)),\n",
    "    }\n",
    "\n",
    "def run_all_evaluations_and_write():\n",
    "    print(\"  🔍 Starting evaluation of all tasks\")\n",
    "    rows = []\n",
    "\n",
    "    tasks = [\"sum\"] + [f\"h{str(n).zfill(2)}\" for n in range(1, 27)]\n",
    "    print(f\"  Tasks to evaluate: {len(tasks)} tasks\")\n",
    "    \n",
    "    for i, task in enumerate(tasks, 1):\n",
    "        print(f\"    [{i:2d}/27] Evaluating task '{task}'...\")\n",
    "        task_dir = ROOT_OUT_DIR / task\n",
    "        try:\n",
    "            if not (task_dir.exists() and list(task_dir.glob(\"final_full_with_nb_K*/summary.json\"))):\n",
    "                print(f\"      Skipped: Final model not found\")\n",
    "                continue\n",
    "            y_val, yhat = evaluate_single_task_val(task)\n",
    "            m = compute_metrics(y_val, yhat)\n",
    "            m[\"task\"] = task\n",
    "            rows.append(m)\n",
    "            print(f\"      Completed: RMSE={m['rmse']:.6f}  MAE={m['mae']:.6f}  sMAPE={m['smape']:.6f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"      Error: {e}\")\n",
    "\n",
    "    print(f\"  Running aggregate evaluation...\")\n",
    "    try:\n",
    "        y_true_sum, yhat_sum = evaluate_horizon_sum_vs_sumval_fixed()\n",
    "        m_sum = compute_metrics(y_true_sum, yhat_sum)\n",
    "        m_sum[\"task\"] = \"h_sum_vs_sum_val\"\n",
    "        rows.append(m_sum)\n",
    "        print(f\"  Aggregate evaluation completed: RMSE={m_sum['rmse']:.6f}  MAE={m_sum['mae']:.6f}  sMAPE={m_sum['smape']:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Aggregate evaluation error: {e}\")\n",
    "\n",
    "    if rows:\n",
    "        print(f\"  Aggregating evaluation results...\")\n",
    "        df_metrics = pd.DataFrame(rows)[[\n",
    "            \"task\",\"n_val\",\"rmse\",\"mae\",\"smape\",\"r2\",\"bias_mean\",\"sum_true\",\"sum_pred\",\"sum_diff\"\n",
    "        ]].sort_values(\"task\").reset_index(drop=True)\n",
    "        df_metrics.to_csv(EVAL_CSV_PATH, index=False)\n",
    "        with open(EVAL_JSON_PATH, \"w\") as f:\n",
    "            json.dump({\"metrics\": rows}, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"  Aggregated CSV: {EVAL_CSV_PATH.resolve()}\")\n",
    "        print(f\"  JSON:     {EVAL_JSON_PATH.resolve()}\")\n",
    "        print(f\"  Evaluation completed: {len(rows)} tasks\")\n",
    "    else:\n",
    "        print(\"  No output targets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b89c330-e624-4861-bdbb-a5f2f510c2eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c23176-f434-49de-be0d-bea2a8885a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Time Series Leak Prevention Machine Learning Pipeline Started\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Output directory: {ROOT_OUT_DIR}\")\n",
    "    print(f\"Number of tasks to process: 27 (sum + h1-h26)\")\n",
    "    print(f\"Target variable base: {TARGET_BASE}\")\n",
    "    print(f\"LightGBM settings: {LGB_NUM_BOOST_ROUND} training rounds, early_stopping={LGB_EARLY_STOP_ROUNDS}\")\n",
    "    print(f\"K candidates: {K_CANDIDATES}\")\n",
    "    print(f\"NB top features: {NB_TOP}\")\n",
    "    print(\"Time series leak prevention: strict train/val split, no date crossing\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=HessianInversionWarning)\n",
    "\n",
    "    tasks = [\"sum\"] + [f\"h{str(n).zfill(2)}\" for n in range(1, 27)]\n",
    "    print(f\"Task list to process: {tasks}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, task in enumerate(tasks, 1):\n",
    "        print(f\"\\n[{i:2d}/27] Starting task '{task}'...\")\n",
    "        try:\n",
    "            run_pipeline_for_task(task)\n",
    "            print(f\"[{i:2d}/27] Task '{task}' completed\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{i:2d}/27] Task '{task}' error: {e}\")\n",
    "        finally:\n",
    "            gc.collect()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Training phase completed\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Output root: {ROOT_OUT_DIR.resolve()}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Validation phase started\")\n",
    "    print(\"=\" * 80)\n",
    "    run_all_evaluations_and_write()\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Validation of all tasks and aggregate completed\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Validation CSV: {EVAL_CSV_PATH.resolve()}\")\n",
    "# --- Set warnings to be hidden ---\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=HessianInversionWarning)\n",
    "\n",
    "# --- Execute pipeline ---\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "General",
   "language": "python",
   "name": "general"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
